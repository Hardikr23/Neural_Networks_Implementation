{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af85173",
   "metadata": {},
   "source": [
    "<h1>Task 1 : Loading the Wine dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d6f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine_data = load_wine()\n",
    "print(wine_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45474b",
   "metadata": {},
   "source": [
    "Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cc9914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data[\"target_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f45056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(wine_data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82b5456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(wine_data[\"data\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f078a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(wine_data[\"data\"][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138e0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1dfc0",
   "metadata": {},
   "source": [
    "<h1>Task 2 : Splitting the dataset into training and test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fda1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine_data[\"data\"], wine_data[\"target\"], random_state = 311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56924ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(133,)\n",
      "(45, 13)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b118c5e",
   "metadata": {},
   "source": [
    "<h1>Task 3 : Using the MLP Classifier and cross_val_score</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38ba8e",
   "metadata": {},
   "source": [
    "<h3>Task 3.1 : Applying the MLPClassifier on Wine dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862a8cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=311)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 311)\n",
    "mlp_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04578a9e",
   "metadata": {},
   "source": [
    "<h3>Task 3.2 : Finding the cross_val_score for default model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c232c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of default Model :  0.15754985754985762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "cross_scores = cross_val_score(mlp_model, x_train, y_train, cv=5)\n",
    "accuracy = np.mean(cross_scores)\n",
    "print(\"The error rate of default Model : \",1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f009da4",
   "metadata": {},
   "source": [
    "<h1>Task 4 : Trying different parameter values for the max_iter in MLPClassifier to get rid of the warning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ec95c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  500\n",
      "Average Score : 0.9404558404558404\n",
      "Error Rate : 0.05954415954415959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  700\n",
      "Average Score : 0.97008547008547\n",
      "Error Rate : 0.02991452991453003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  900\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  1100\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  1300\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n",
      "Max Iter :  1500\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n",
      "Max Iter :  1700\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    }
   ],
   "source": [
    "max_iter = [500, 700, 900, 1100, 1300, 1500, 1700]\n",
    "for iters in max_iter:\n",
    "    param_mlp_model = MLPClassifier(random_state = 311, max_iter = iters)\n",
    "    param_mlp_model.fit(x_train, y_train)\n",
    "    cross_scores = cross_val_score(param_mlp_model, x_train, y_train, cv=5)\n",
    "    print(\"Max Iter : \",iters)\n",
    "    print(\"Average Score :\",np.mean(cross_scores))\n",
    "    print(\"Error Rate :\", 1-np.mean(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f95a1",
   "metadata": {},
   "source": [
    "<h2>Observations</h2><br>\n",
    "In the above outputs We can see the warning msgs for each iteration of cross_val for each value of max_iter.<br>\n",
    "We can observe that the model gives warnings for the first 5 values(500, 700, 900, 1100, 1300) and finally on the last 2 iterations(1500 and 1700).<br> \n",
    "So we can say that <b>max_iter : 1500</b> can be the minimum value for <b>randon_state : 311</b> with <b>Error Rate : 0.0373</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012caed",
   "metadata": {},
   "source": [
    "<h1>Task 5 : Finding the test error rate of the MLPClassifier with the modified values of max_iter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b779e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model when using modified parameters : 0.9555555555555556\n",
      "Test Error rate of model : 0.0444444444444444\n"
     ]
    }
   ],
   "source": [
    "new_mlp_model = MLPClassifier(random_state=311, max_iter = 1500)\n",
    "new_mlp_model.fit(x_train, y_train)\n",
    "acc = new_mlp_model.score(x_test, y_test)\n",
    "print(\"The accuracy of the model when using modified parameters :\",acc)\n",
    "err_rate = 1 - acc\n",
    "print(\"Test Error rate of model :\",err_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03b67d",
   "metadata": {},
   "source": [
    "<h3>Observations</h3>\n",
    "\n",
    "We can see that the error rate in step 4 is 0.037321<br>\n",
    "And, the Test Error Rate in step 5 is 0.044444<br>\n",
    "\n",
    "The possible reason that the error rate is lower in the training set can be beacuse it is calculated using cross_val_score, where our training data is further split into training and test set thus decreasing the size of the traning set. This may lead to out model just memorizing the data hence giving better results.<br>\n",
    "But in the case where we calculate the test error rate, our model has never seen the test set and is not able to predict as good as the one in step 4.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9b6384",
   "metadata": {},
   "source": [
    "<h1>Task 6 : Creating a pipeline for MLPClassifier with data normalization.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ee099",
   "metadata": {},
   "source": [
    "Trying different scaler methods for wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e960b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c6dca",
   "metadata": {},
   "source": [
    "<h3>1. MinMax Scaler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27a75c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with MinMAx Scaler\n",
    "mm_scaler_pipeline = Pipeline([(\"MinMaxScaler\", MinMaxScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 1500)) \\\n",
    "                     ])\n",
    "mm_scaler_pipeline.fit(x_train, y_train)\n",
    "print(mm_scaler_pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b1ac3",
   "metadata": {},
   "source": [
    "<h3>2. Normalizer Scaler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13606be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Normalizer Scaler\n",
    "n_scaler_pipeline = Pipeline([(\"Normalizer\", Normalizer()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "n_scaler_pipeline.fit(x_train, y_train)\n",
    "print(n_scaler_pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d70434",
   "metadata": {},
   "source": [
    "<h3>3. StandardScaler Scaler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d158d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Standard Scaler\n",
    "ss_scaler_pipeline = Pipeline([(\"StandardScaler\", StandardScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "ss_scaler_pipeline.fit(x_train, y_train)\n",
    "print(ss_scaler_pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b675ea2",
   "metadata": {},
   "source": [
    "<h3>4. Robust Scaler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac195a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Standard Scaler\n",
    "rs_scaler_pipeline = Pipeline([(\"Robust\", RobustScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "rs_scaler_pipeline.fit(x_train, y_train)\n",
    "print(rs_scaler_pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816fadf",
   "metadata": {},
   "source": [
    "<h3>Observations</h3>\n",
    "From the above 4 cells, we can see how each scaler performs with our wine data when applied on the pipeline.<br>\n",
    "We can observe that the <b>MinMax Scaler and Robust Scaler</b> have the same and maximun accuracy. So we can select anyone of them to perform GridSearchCV on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a1ee6",
   "metadata": {},
   "source": [
    "<h1>Task 7 : Using GridSearch and Cross Validation to tune the alpha parameter.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195214f",
   "metadata": {},
   "source": [
    "Implementing GridSearchCV using the Normalizer Scaler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1ac3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalizer\n",
      "Best Parameter value : {'MLP__alpha': 0.01}\n",
      "Model Accuracy : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "alpha_grid = {'MLP__alpha':[1000, 100, 10, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "grid_search_pipe = GridSearchCV(n_scaler_pipeline, alpha_grid, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(x_train, y_train)\n",
    "print(\"For Normalizer\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f092988",
   "metadata": {},
   "source": [
    "Implementing GridSearchCV using the Standard Scaler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2fa5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Standard Scaler\n",
      "Best Parameter value : {'MLP__alpha': 10}\n",
      "Model Accuracy : 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha_grid = {'MLP__alpha':[1000, 100, 10, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "grid_search_pipe = GridSearchCV(mm_scaler_pipeline, alpha_grid, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(x_train, y_train)\n",
    "print(\"For Standard Scaler\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ae6ed",
   "metadata": {},
   "source": [
    "<h1>Task 8 : Implementing Cross-Conformal Predictor</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fba72e",
   "metadata": {},
   "source": [
    "<h3>1. Creating k-folds of the wine training dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89769bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88e4cd",
   "metadata": {},
   "source": [
    "By default the KFold class creates 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5192d2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e37e4976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08774258860514446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating an empty array to store all false p-values\n",
    "false_p_vals = []\n",
    "all_test_samples_p = [] # Can be removed\n",
    "\n",
    "# For loop to iterate over the folds created using the KFold object\n",
    "for rest_index, fold_index in kf.split(x_train):\n",
    "#     Creating the training and test set by using the row indices which are not part of the current fold\n",
    "    x_rest = x_train[rest_index]\n",
    "    y_rest = y_train[rest_index]\n",
    "    \n",
    "#   We use the GridSearchCV object for Standard Scaler for the wine dataset\n",
    "    grid_search_pipe.fit(x_rest, y_rest)\n",
    "#     A list to store all the prediccted values for the test samples\n",
    "    pred_list = []\n",
    "#     Initialising an empty array of size 45x3 to store the sum of all the probility values for all folds\n",
    "    test_sample_p = np.zeros((len(x_test),len(np.unique(y_rest))))\n",
    "\n",
    "#     Loop to iterate over all the test samples\n",
    "    for test_idx in range(len(x_test)):\n",
    "        \n",
    "        conformity_list = [] # Can be removed\n",
    "#         Creating the feature and label set for the current fold\n",
    "        x_fold = x_train[fold_index]\n",
    "        y_fold = y_train[fold_index]\n",
    "        \n",
    "#         Creating a copy of the xfold which has one extra element which is the test sample\n",
    "        copy_x_fold = np.append(x_fold, [x_test[test_idx]], axis = 0)\n",
    "#         Getting the predicted probabilities for the test sample we appended at the end\n",
    "        predict_proba_list = grid_search_pipe.predict_proba(copy_x_fold)[-1]\n",
    "\n",
    "        test_sample_p[test_idx,:] = test_sample_p[test_idx,:] + predict_proba_list\n",
    "        \n",
    "        predict_proba_list = list(predict_proba_list)\n",
    "#         Getting the index of the class with the max probability\n",
    "        max_p_index = predict_proba_list.index(max(predict_proba_list))\n",
    "        pred_list.append(predict_proba_list[max_p_index])\n",
    "        del predict_proba_list[max_p_index]\n",
    "#         Appending the \n",
    "        false_p_vals = false_p_vals + predict_proba_list\n",
    "        \n",
    "        \n",
    "test_sample_p = test_sample_p/5\n",
    "print(np.mean(false_p_vals))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100)  \n",
    "err = np.zeros(100)  \n",
    "for k in range(100):\n",
    "    eps[k] = k/100 \n",
    "    err[k] = 0  \n",
    "    for j in range(y_test.shape[0]):\n",
    "        if (test_sample_p[j,y_test[j]] <= eps[k]):  \n",
    "            err[k] = err[k] + 1 \n",
    "    err[k] = err[k] / y_test.shape[0]\n",
    "\n",
    "figure = plt.plot(eps,err)\n",
    "plt.title('Calibration Curve')\n",
    "plt.xlabel('Significance Level')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48391d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f80282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9f708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "008e4337",
   "metadata": {},
   "source": [
    "<h1>USPS Digits Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0dd2cd",
   "metadata": {},
   "source": [
    "<h1>Task 1 : Load the image dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97dac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.genfromtxt(\"/Users/hardikrathod/Desktop/RHUL/ML/Labs and Assignments/Assignment_3/zip.train\")\n",
    "test_data = np.genfromtxt(\"/Users/hardikrathod/Desktop/RHUL/ML/Labs and Assignments/Assignment_3/zip.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c89428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.    -1.    -1.    -1.    -0.813 -0.671 -0.809 -0.887 -0.671 -0.853\n",
      " -1.    -1.    -0.774 -0.18   0.052 -0.241 -1.    -1.    -1.    -1.\n",
      "  0.392  1.     0.857  0.727  1.     0.805  0.613  0.613  0.86   1.\n",
      "  1.     0.396 -1.    -1.    -1.    -1.    -0.548  1.     1.     1.\n",
      "  1.     1.     1.     1.     1.     1.     1.     0.875 -0.957 -1.\n",
      " -1.    -1.    -0.786  0.961  1.     1.     1.     0.727  0.403  0.403\n",
      "  0.171 -0.314 -0.314 -0.94  -1.    -1.    -1.    -1.    -0.298  1.\n",
      "  1.     1.     0.44   0.056 -0.755 -1.    -1.    -1.    -1.    -1.\n",
      " -1.    -1.    -1.    -1.     0.366  1.     1.     1.     1.     1.\n",
      "  0.889 -0.081 -0.92  -1.    -1.    -1.    -1.    -1.    -1.    -1.\n",
      " -0.396  0.886  0.974  0.851  0.851  0.95   1.     1.     0.539 -0.754\n",
      " -1.    -1.    -1.    -1.    -1.    -1.    -1.    -0.886 -0.505 -1.\n",
      " -1.    -0.649  0.405  1.     1.     0.653 -0.838 -1.    -1.    -1.\n",
      " -1.    -1.    -1.    -1.    -1.    -1.    -1.    -1.    -1.    -0.55\n",
      "  0.993  1.     0.618 -0.869 -1.    -0.96  -0.512  0.134 -0.343 -0.796\n",
      " -1.    -1.    -1.    -1.    -1.    -1.    -0.432  0.994  1.     0.223\n",
      " -1.     0.426  1.     1.     1.     0.214 -1.    -1.    -1.    -1.\n",
      " -1.    -1.    -1.     0.292  1.     0.967 -0.88   0.449  1.     0.896\n",
      " -0.094 -0.75  -1.    -1.    -1.    -1.    -1.    -1.    -1.    -0.627\n",
      "  1.     1.     0.198 -0.105  1.     1.     1.     0.639 -0.168 -0.314\n",
      " -0.446 -1.    -1.    -0.999 -0.337  0.147  0.996  1.     0.667 -0.808\n",
      "  0.065  0.993  1.     1.     1.     1.     0.996  0.97   0.97   0.97\n",
      "  0.998  1.     1.     1.     0.109 -1.    -1.    -0.83  -0.242  0.35\n",
      "  0.8    1.     1.     1.     1.     1.     1.     1.     1.     0.616\n",
      " -0.93  -1.    -1.    -1.    -1.    -1.    -0.858 -0.671 -0.671 -0.033\n",
      "  0.761  0.762  0.126 -0.095 -0.671 -0.828 -1.   ]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5473d7",
   "metadata": {},
   "source": [
    "Above is the output of one of the rows from the training data.<br>\n",
    "We can see that the first element of this observation is a number and all other look like pixel values<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d166963f",
   "metadata": {},
   "source": [
    "<h1>Task 2 : Merge the train and test sets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1de185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 257)\n"
     ]
    }
   ],
   "source": [
    "full_data = np.concatenate((training_data, test_data))\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f52e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 5. 4. 7. 3.]\n"
     ]
    }
   ],
   "source": [
    "all_labels = np.array([row[0] for row in full_data])\n",
    "all_features = np.array([row[1:] for row in full_data])\n",
    "print(all_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f84315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6973, 256)\n",
      "(6973,)\n",
      "(2325, 256)\n",
      "(2325,)\n"
     ]
    }
   ],
   "source": [
    "d_x_train, d_x_test, d_y_train, d_y_test = train_test_split(all_features, all_labels, random_state= 311)\n",
    "print(d_x_train.shape)\n",
    "print(d_y_train.shape)\n",
    "print(d_x_test.shape)\n",
    "print(d_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f84bdc",
   "metadata": {},
   "source": [
    "<h1>Task 3 : Using the MLP Classifier and cross_val_score</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c4ba0",
   "metadata": {},
   "source": [
    "<h3>Task 3.1 : Applying the MLPClassifier on Wine dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f4df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=311)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mlp_model = MLPClassifier(random_state = 311)\n",
    "d_mlp_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd82204",
   "metadata": {},
   "source": [
    "<h3>Task 3.2 : Finding the cross_val_score for default model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa88500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957694471441868\n"
     ]
    }
   ],
   "source": [
    "d_cross_scores = cross_val_score(d_mlp_model, d_x_train, d_y_train, cv=5)\n",
    "print(np.mean(d_cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f03dff",
   "metadata": {},
   "source": [
    "<h1>Task 4 :</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aef33ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  500\n",
      "Average Score : 0.9404558404558404\n",
      "Error Rate : 0.05954415954415959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  700\n",
      "Average Score : 0.97008547008547\n",
      "Error Rate : 0.02991452991453003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  900\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  1100\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikrathod/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iter :  1300\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n",
      "Max Iter :  1500\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n",
      "Max Iter :  1700\n",
      "Average Score : 0.9626780626780628\n",
      "Error Rate : 0.037321937321937226\n"
     ]
    }
   ],
   "source": [
    "max_iter = [500, 700, 900, 1100, 1300, 1500, 1700]\n",
    "for iters in max_iter:\n",
    "    param_mlp_model = MLPClassifier(random_state = 311, max_iter = iters)\n",
    "    param_mlp_model.fit(x_train, y_train)\n",
    "    cross_scores = cross_val_score(param_mlp_model, x_train, y_train, cv=5)\n",
    "    print(\"Max Iter : \",iters)\n",
    "    print(\"Average Score :\",np.mean(cross_scores))\n",
    "    print(\"Error Rate :\", 1-np.mean(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9ae5f",
   "metadata": {},
   "source": [
    "<h3>Observations</h3><br>\n",
    "In the above outputs We can see the warning msgs for each iteration of cross_val for each value of max_iter.<br>\n",
    "We can observe that the model gives warnings for the first 5 values(500, 700, 900, 1100, 1300) and finally on the last 2 iterations(1500 and 1700).<br> \n",
    "So we can say that <b>max_iter : 1500</b> can be the minimum value for <b>randon_state : 311</b> with <b>Error Rate : 0.04501</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73743ecd",
   "metadata": {},
   "source": [
    "<h1>Task 5 : Finding the test error rate of the MLPClassifier with the modified values of max_iter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d3866cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664516129032258\n",
      "Test Error rate of model : 0.03354838709677421\n"
     ]
    }
   ],
   "source": [
    "d_new_mlp_model = MLPClassifier(random_state=311, max_iter = 1500)\n",
    "d_new_mlp_model.fit(d_x_train, d_y_train)\n",
    "d_acc = d_new_mlp_model.score(d_x_test, d_y_test)\n",
    "print(d_acc)\n",
    "d_err_rate = 1 - d_acc\n",
    "print(\"Test Error rate of model :\",d_err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b16ce16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703225806451613\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with MinMAx Scaler\n",
    "d_mm_scaler_pipeline = Pipeline([(\"MinMaxScaler\", MinMaxScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 1500)) \\\n",
    "                     ])\n",
    "d_mm_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(d_mm_scaler_pipeline.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8371f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655913978494624\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Normalizer Scaler\n",
    "d_n_scaler_pipeline = Pipeline([(\"Normalizer\", Normalizer()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "d_n_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(d_n_scaler_pipeline.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "833af538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703225806451613\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Standard Scaler\n",
    "d_ss_scaler_pipeline = Pipeline([(\"StandardScaler\", StandardScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "d_ss_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(d_ss_scaler_pipeline.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ff27fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617204301075268\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with Robust Scaler\n",
    "d_rs_scaler_pipeline = Pipeline([(\"Robust\", RobustScaler()), \\\n",
    "                      (\"MLP\", MLPClassifier(random_state=311, max_iter = 3000)) \\\n",
    "                     ])\n",
    "d_rs_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(d_rs_scaler_pipeline.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73072615",
   "metadata": {},
   "source": [
    "<h3>Observations</h3>\n",
    "From the above 4 cells, we can see how each scaler performs with our USPS data when applied on the pipeline.<br>\n",
    "We can observe that the MinMax Scaler and Standard Scaler have the same accuracy. So we can select anyone of them to perform GridSearchCV on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a6673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalizer\n",
      "{'MLP__alpha': 0.01}\n",
      "0.9668817204301076\n"
     ]
    }
   ],
   "source": [
    "d_grid_search_pipe = GridSearchCV(d_n_scaler_pipeline, alpha_grid, cv=5, n_jobs = -2)\n",
    "d_grid_search_pipe.fit(d_x_train, d_y_train)\n",
    "print(\"For Normalizer\")\n",
    "print(d_grid_search_pipe.best_params_)\n",
    "print(d_grid_search_pipe.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09c677a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Standard Scaler\n",
      "{'MLP__alpha': 0.1}\n",
      "0.9716129032258064\n"
     ]
    }
   ],
   "source": [
    "alpha_grid = {'MLP__alpha':[1000, 100, 10, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "d_grid_search_pipe = GridSearchCV(d_ss_scaler_pipeline, alpha_grid, cv=5, n_jobs = -2)\n",
    "d_grid_search_pipe.fit(d_x_train, d_y_train)\n",
    "print(\"For Standard Scaler\")\n",
    "print(d_grid_search_pipe.best_params_)\n",
    "print(d_grid_search_pipe.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0e6a2",
   "metadata": {},
   "source": [
    "<h1>Task 8 : Implementing Cross-Conformal Predictor</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01f824",
   "metadata": {},
   "source": [
    "1. Creating k-folds of the wine training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "738b137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_kf = KFold(shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e34257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028503111269489127\n"
     ]
    }
   ],
   "source": [
    "false_p_vals = []\n",
    "all_test_samples_p = [] # Can be removed\n",
    "for rest_index, fold_index in d_kf.split(d_x_train):\n",
    "    x_rest = d_x_train[rest_index]\n",
    "    y_rest = d_y_train[rest_index]\n",
    "    \n",
    "#   We use the GridSearchCV object for Standard Scaler for the wine dataset\n",
    "    grid_search_pipe.fit(x_rest, y_rest)\n",
    "    pred_list = []\n",
    "    test_sample_p = np.zeros((len(d_x_test),len(np.unique(y_rest))))\n",
    "\n",
    "    for test_idx in range(len(d_x_test)):\n",
    "        \n",
    "        conformity_list = [] # Can be removed\n",
    "        x_fold = d_x_train[fold_index]\n",
    "        y_fold = d_y_train[fold_index]\n",
    "        copy_x_fold = np.append(x_fold, [d_x_test[test_idx]], axis = 0)\n",
    "        predict_proba_list = d_grid_search_pipe.predict_proba(copy_x_fold)[-1]\n",
    "\n",
    "        test_sample_p[test_idx,:] = test_sample_p[test_idx,:] + predict_proba_list\n",
    "        \n",
    "        predict_proba_list = list(predict_proba_list)\n",
    "        max_p_index = predict_proba_list.index(max(predict_proba_list))\n",
    "        pred_list.append(predict_proba_list[max_p_index])\n",
    "        del predict_proba_list[max_p_index]\n",
    "        false_p_vals = false_p_vals + predict_proba_list\n",
    "        \n",
    "        \n",
    "test_sample_p = test_sample_p/kf.get_n_splits()\n",
    "print(np.mean(false_p_vals))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ca0b87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfsElEQVR4nO3de5hcdZ3n8fcn3QmY+5UIIZ0ETMCwj9yacBnlqnJRCc7oymVEWd1MFFhWhxmQHR1HZtQZn3HVBcxGFlkZBUUQI0aRGQVUQBOUWwhmYyDQJEAukJCEkK6q7/5xTidl0111OqnqSp36vJ6nn9Sp86tzvqcKft/6Xep3FBGYmVnrGtLoAMzMrLGcCMzMWpwTgZlZi3MiMDNrcU4EZmYtzonAzKzFORFYU5MUkt6UPl4g6dPp45MlddX53BdI+lk9z2E2GJwIrOEknS9pqaQtktZK+omktw70OBExPyKurlOM09Ok0152vm9HxDvrdL7Rkr4i6Zn0fVmZbk+sx/mstTkRWENJ+iTwFeDzwGSgA7gOmDvIcbQN5vkqkTQM+A/gMOAMYDRwArABmLMbx2uvXspamROBNYykMcDngIsj4vaI2BoR3RHxo4j4m7TMHEkPSHo5bS1ck1aUfR3vRkn/2Ou5qyStl/S0pAt6lf26pMWStgKnSHqXpN9L2izpWUmfLTvUfem/L6ff0I+X9GFJvyo75gmSlkjalP57Qtm+eyRdLenXkl6R9LMK3+4vJEmI742IJyKiFBEvRsTVEbE4Pd7OLrHe197TLSbpCknPA9+UtFzSu8vKt6fvy1Hp9nGS7k/f50ckndxPbJZDTgTWSMcD+wI/qFCmCHwCmJiWPw34eMbjvzF93RTgQ8BCSYeU7T8f+CdgFPArYCtJJTwWeBfwMUnnpGVPTP8dGxEjI+KB8hNJGg/8GPgaMAH4MvBjSRN6ne8iYD9gGHB5P3G/HfhpRGzJeJ19eSMwHpgGzANuBs4r2386sD4ifidpShr7P6avuRy4TdKkPTi/NREnAmukCSSVUaG/AhHxUEQ8GBGFiHga+N/ASQM4x6cj4rWIuJeksvvPZft+GBG/Tr9xb4+IeyLisXT7UZLKM+u53gX8v4i4KY31ZuBJ4D1lZb4ZESsi4lXge8AR/RxrArB2ANfYlxLw9+m1vwp8Bzhb0vB0//npcwB/CSyOiMXptd8NLAXO2sMYrEk4EVgjbQAmVurDljRL0p2Snpe0mWQsIeuA6UsRsbVsezVwQNn2s73OdaykX0haJ2kTMH8A5zogPX651SStkR7Plz3eBozs51gbgP0znrc/6yJie89GRKwElgPvSZPB2exKBNOA96fdQi9Lehl4aw1isCbhRGCN9ACwHTinQpmvk3yznhkRo4GrAGU8/jhJI8q2O4A1Zdu9l979DrAImBoRY4AFZeeqtkzvGpIKtVwH8FzGWMv9O3B6r9h72wYML9t+Y6/9fcXb0z00F3giTQ6QJMSbImJs2d+IiPjibsRuTciJwBomIjYBnwGulXSOpOGShko6U9K/pMVGAZuBLZIOBT42wNP8g6Rhkt4GvBu4tULZUcDGiNguaQ5J90mPdSTdLQf189rFwKx0Kmy7pA8As4E7BxgvwE0klfNtkg6VNETShHTgu6e75mHgfEltks4gWxfWLcA7Sd7D75Q9/28kLYXT0+Ptmw44H7gbsVsTciKwhoqILwOfBP6OpLJ9FrgEuCMtcjlJhfwK8A3guwM4/PPASyTf1r8NzI+IJyuU/zjwOUmvkCSo75XFuY1kYPnXaffJcb2uYwNJovlrkq6dvwXeHRHrBxBvz7FeIxkwfhK4myQR/pakm+o3abHLSMYfXgYuYNf7Vem4a0laYSdQ9j5GxLMkrYSr2PUZ/A2uH1qGfGMaM7PW5oxvZtbinAjMzFqcE4GZWYtzIjAza3FNtxjVxIkTY/r06Y0Ow8ysqTz00EPrI6LPZUOaLhFMnz6dpUuXNjoMM7OmIqn3L993cteQmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtbi6JQJJN0h6UdLj/eyXpK+lN+V+tOeWeWZmNrjq2SK4keTG2/05E5iZ/s0jWXfezMwGWd1+RxAR90maXqHIXOBbkSx/+qCksZL2T5fKtRq5d8U6Hnp6Y6PDMLMa6Jw+nhNn1f5W0o38QdkU/vRWgV3pc69LBJLmkbQa6OjoGJTg8uJzP1rGH9dtRVnv6WVme635Jx2cu0TQV9XU580RImIhsBCgs7PTN1AYgB3FEn9+5BS+/IEjGh2Kme2lGjlrqAuYWrZ9IH96P1mrgUIxaBvi5oCZ9a+RiWARcGE6e+g4YJPHB2qvUAra25wIzKx/desaknQzcDIwUVIX8PfAUICIWEBys++zgJXANuCiesXSyoqloH2Ify5iZv2r56yh86rsD+Diep3fEt3FkruGzKwif1XMuWIpGOquITOrwIkg55LBYn/MZtY/1xA5VyiVaHfXkJlV4ESQY6VSUAo8a8jMKnIiyLFCKfntnVsEZlaJE0GOFXsSQZs/ZjPrn2uIHOsulQC3CMysMieCHCsWkxaBf0dgZpU4EeRYwV1DZpaBa4gcK7hryMwycCLIsULRs4bMrDonghzb1TXkRGBm/XMiyLFi2jXkJSbMrBLXEDnW0yIY6q4hM6vAiSDHCp4+amYZOBHk2M4WgaePmlkFriFyrFDsGSNwi8DM+udEkGNedM7MsnAiyDEvOmdmWbiGyLFudw2ZWQZOBDlW3DlY7ERgZv1zIsixbk8fNbMMnAhybOcYgX9ZbGYVuIbIsZ2rj7pryMwqcCLIMa8+amZZOBHkWE/XkMcIzKwSJ4Ic67lnsZeYMLNKXEPkmFsEZpaFE0GO9YwRDPWsITOrwDVEjvXMGmrzrCEzq8CJIMe86JyZZVHXRCDpDEl/kLRS0pV97B8j6UeSHpG0TNJF9Yyn1Xj6qJllUbdEIKkNuBY4E5gNnCdpdq9iFwNPRMThwMnAv0oaVq+YWk3Bg8VmlkE9WwRzgJURsSoidgC3AHN7lQlglCQBI4GNQKGOMbWUYqlE+xCRvL1mZn2rZyKYAjxbtt2VPlfuGuDNwBrgMeCyiCj1PpCkeZKWSlq6bt26esWbO4ViuDVgZlXVMxH0VQNFr+3TgYeBA4AjgGskjX7diyIWRkRnRHROmjSp1nHmVqEUHh8ws6rqmQi6gKll2weSfPMvdxFweyRWAk8Bh9YxppZSKJZ8dzIzq6qetcQSYKakGekA8LnAol5lngFOA5A0GTgEWFXHmFqKWwRmlkV7vQ4cEQVJlwB3AW3ADRGxTNL8dP8C4GrgRkmPkXQlXRER6+sVU6splsJLUJtZVXVLBAARsRhY3Ou5BWWP1wDvrGcMray7GL4pjZlV5Voix4qlkmcNmVlVTgQ51u2uITPLwIkgx4pFDxabWXVOBDmWzBryR2xmlbmWyLFCqeSuITOryokgx4olLzFhZtU5EeRYd7Hku5OZWVWuJXLMLQIzy8KJIMcKnj5qZhk4EeRYwdNHzSwDJ4IcK5SCNo8RmFkVriVyrFAsMdRdQ2ZWhRNBjnmw2MyycCLIsUIpGOob05hZFa4lcqxQ9OqjZladE0GO+Q5lZpaFE0GO+XcEZpaFE0GOFYolrz5qZlW5lsixoruGzCwDJ4Ic6y4Fbe4aMrMqnAhyzC0CM8vCiSCnIiJNBP6Izawy1xI5VSgFgFsEZlaVE0FOFXsSgX9ZbGZVuJbIqe5iCXCLwMyqcyLIqZ4WgZeYMLNqnAhyqruYJAIvQ21m1TgR5NSuFoE/YjOrzLVEThVK6RiBWwRmVoUTQU4Vip4+ambZVE0ESvylpM+k2x2S5mQ5uKQzJP1B0kpJV/ZT5mRJD0taJunegYVv/Sl4sNjMMsrSIrgOOB44L91+Bbi22osktaXlzgRmA+dJmt2rzNj0+GdHxGHA+zNHbhX1dA35DmVmVk2WWuLYiLgY2A4QES8BwzK8bg6wMiJWRcQO4BZgbq8y5wO3R8Qz6bFfzBy5VdTTNeQWgZlVkyURdKff7gNA0iSglOF1U4Bny7a70ufKzQLGSbpH0kOSLuzrQJLmSVoqaem6desynNp6Zg15+qiZVZMlEXwN+AGwn6R/An4FfCHD6/qqgaLXdjtwNPAu4HTg05Jmve5FEQsjojMiOidNmpTh1NbTNeTpo2ZWTXu1AhHxbUkPAaeRVO7nRMTyDMfuAqaWbR8IrOmjzPqI2ApslXQfcDiwIkvw1j/PGjKzrLLMGropIp6MiGsj4pqIWC7ppgzHXgLMlDRD0jDgXGBRrzI/BN4mqV3ScOBYIEuSsSq8+qiZZVW1RQAcVr6RjhccXe1FEVGQdAlwF9AG3BARyyTNT/cvSJPKT4FHScYdro+Ixwd6EfZ6OxOBxwjMrIp+E4GkTwFXAW+QtJldff47gIVZDh4Ri4HFvZ5b0Gv7S8CXBhCzZVDs+WWxxwjMrIp+a4mI+EJEjAK+FBGjI2JU+jchIj41iDHabuj29FEzyyjLYPGnJI0DZgL7lj1/Xz0Dsz1TdNeQmWVUNRFI+ihwGcmsn4eB44AHgFPrGpntkV2Dxe4aMrPKstQSlwHHAKsj4hTgSMC/6trLFXyHMjPLKEsi2B4R2wEk7RMRTwKH1Dcs21OeNWRmWWWZPtqVLg53B3C3pJd4/Q/DbC+z6wdl7hoys8qyDBa/N334WUm/AMYAP6lrVLbHijuXmHCLwMwqG9DXxYi4l2QV0sXVylpjFbzonJll1G8ikHSqpBWStkj6N0mzJS0lWXDu64MXou0OL0NtZllVahH8KzAPmAB8H3gQuCkijo6I2wcjONt9u1oEHiMws8oqjRFERNyTPr5D0rqI+OogxGQ10DN91C0CM6umUiIYK+nPy7ZVvu1Wwd7Nq4+aWVaVEsG9wHv62Q7AiWAvViwFbUOE5ERgZpX1mwgi4qLBDMRqq7tUcreQmWXikcScKhaDoU4EZpaBE0FOFdKuITOzaiomAklDJJ0wWMFY7RRKJdo9ddTMMqhYU0REieT3BNZkiqXwjCEzyyTLV8afSfoLefpJU+kuOhGYWTZZVh/9JDACKEp6leTexRERo+same2RYincNWRmmWRZfXTUYARitdVdLLlFYGaZZGkRIOls4MR0856IuLN+IVktFD1ryMwyqtp3IOmLJLerfCL9uyx9zvZiBXcNmVlGWVoEZwFHpDOIkPR/gd8DV9YzMNszBXcNmVlGWb8yji17PKYOcViNJS0CJwIzqy5Li+DzwO/T21SKZKzgU3WNyvZYwdNHzSyjiolA0hCgBBwHHEOSCK6IiOcHITbbAx4sNrOsKiaCiChJuiQivgcsGqSYrAYKpRIjhmaaFGZmLS7LGMHdki6XNFXS+J6/ukdme8SLzplZVlm+Mv6X9N+Ly54L4KDah2O1kowRePqomVWXZYzgyoj47iDFYzVSKHn6qJllk2X10YsrlalE0hmS/iBppaR+f3cg6RhJRUnv291z2Z8qlII2Tx81swzqNkYgqQ24FjgTmA2cJ2l2P+X+GbhrgLFbBcWS71BmZtnUc4xgDrAyIlYBSLoFmEuyTEW5S4HbSKanWo0UikGbxwjMLIMsq4/O2M1jTwGeLdvuAo4tLyBpCvBe4FQqJAJJ84B5AB0dHbsZTmsplEoMddeQmWXQ71dGSX9b9vj9vfZ9PsOx+6qFotf2V0h+oFasdKCIWBgRnRHROWnSpAyntqRF4ERgZtVV6js4t+xx7yUlzshw7C5gatn2gcCaXmU6gVskPQ28D7hO0jkZjm1VFHyrSjPLqFLXkPp53Nd2X5YAMyXNAJ4jSSznlxco73aSdCNwZ0TckeHYVoXvUGZmWVVKBNHP4762X//iiIKkS0hmA7UBN0TEMknz0/0LBhqsZec7lJlZVpUSweGSNpN8+39D+ph0e98sB4+IxcDiXs/1mQAi4sNZjmnZFL0MtZll1G8iiIi2wQzEaici0rWG3DVkZtW5psihYinpuXPXkJll4USQQ4WeROCuITPLwIkghwpuEZjZADgR5FCx2JMI/PGaWXWuKXKou1QC3DVkZtk4EeRQz2Cxl5gwsyycCHKoZ4xgqLuGzCwD1xQ5VCgmXUNuEZhZFk4EOeTpo2Y2EE4EOVTwrCEzGwDXFDlUKLlryMyycyLIoZ5ZQ75DmZll4USQQ91FTx81s+ycCHJoV4vAH6+ZVeeaIoc8fdTMBsKJIIe86JyZDYQTQQ7tvB+Bu4bMLAPXFDnUnXYNuUVgZlk4EeRQ0b8sNrMBcCLIoW6PEZjZADgR5FBx5y+L/fGaWXWuKXJo11pDbhGYWXVOBDnk1UfNbCCcCHJo1+8I/PGaWXWuKXKo4OmjZjYATgQ5tPOexe4aMrMMnAhyyPcsNrOBcE2RQ150zswGwokgh7zonJkNRF0TgaQzJP1B0kpJV/ax/wJJj6Z/90s6vJ7xtIpCMRgiGOJEYGYZ1C0RSGoDrgXOBGYD50ma3avYU8BJEfEW4GpgYb3iaSWFUnjqqJllVs/aYg6wMiJWRcQO4BZgbnmBiLg/Il5KNx8EDqxjPC2jWCr5x2Rmllk9E8EU4Nmy7a70uf58BPhJXzskzZO0VNLSdevW1TDEfOouhgeKzSyzeiaCvmqi6LOgdApJIriir/0RsTAiOiOic9KkSTUMMZ+KpfD9is0ss/Y6HrsLmFq2fSCwpnchSW8BrgfOjIgNdYynZRRKJbcIzCyzen5tXALMlDRD0jDgXGBReQFJHcDtwAcjYkUdY2kphWJ46qiZZVa3FkFEFCRdAtwFtAE3RMQySfPT/QuAzwATgOskARQiorNeMbWKYik8WGxmmdWza4iIWAws7vXcgrLHHwU+Ws8YWlG3p4+a2QC4tsihYqnkriEzy8yJIIc8fdTMBsKJIIc8RmBmA+FEkENeYsLMBsK1RQ4Vih4jMLPsnAhyqOCuITMbACeCHEpaBP5ozSwb1xY5VCx51pCZZedEkEOFUjDUXUNmlpETQQ4V/DsCMxsAJ4IcKpRKtHsZajPLyLVFDhVLXn3UzLJzIsghLzFhZgPhRJBDxVIw1NNHzSwj1xY5VCiVaPOsITPLyIkgZ3786FrWb9nBtPHDGx2KmTUJJ4IceXr9Vq647VGOmDqWi/5sRqPDMbMm4USQE9u7i1z8nd/RNkRcc/6RDGv3R2tm2dT1VpU2OEql4B9+9ATL1mzm/3yokwPHuVvIzLJzImhyG7fu4PJbH+HnT77I/JMO5rQ3T250SGbWZJwImtjSpzdy6c2/Z8OWHXxu7mF88LhpjQ7JzJqQE0ETWr1hK//z7hX88JE1dIwfzu0fP4H/NGVMo8MysyblRNAktncXWfL0RhY/tpZbl3bR3ib+6sSDufiUgxm179BGh2dmTcyJYC/23Muv8h/LX+Dfl7/Ib1Zt4LVCiWHtQzhvTgeXnvom9hu9b6NDNLMccCLYi2x6tZulT2/kwVUb+NXKDSxfuxmAgyaO4PxjOzhx1iSOnTGe4cP8sZlZ7bhGaZCXt+1g2ZrNLFuziWVrNvP4c5tYtX4rETCsfQhHTh3LVWcdymlvnszBk0Y2OlwzyzEngkEQETy1fisPrkq+7T+0+iWee/nVnfsPGLMvh00Zw9mHT2HOjPEc2TGWfYe2NTBiM2slTgQ1tH7Layxfu5nVG7bxzMZtPL1+K89s3MbqDdt4tbsIwH6j9uGYGeP54PHTOOyA0Rx2wBjGjxjW4MjNrJU5EeymiGDtpu2seOEVfvPURu5bsY5lazbv3D+sfQgd44czfcJwTjh4IjMnj+TYGeOZMXEEklcGNbO9hxNBBa9s72bVuq2seOEVVq7bwgubtrNh6w42bt3B6g3b2PJaAYD2IeKoaeO4/J2zOGraOGZMHMHkUfsyxDeHMbMm0PKJICLoeulVHntuE8vWbGL52lfoemkbazdt55XthZ3lhrUNYb/R+zBh5D5MHr0vndPGMXPyKGbuN5LZB4z2XH4za1p1TQSSzgC+CrQB10fEF3vtV7r/LGAb8OGI+F09YwLYtqPAnY+s5f4/rufBVRt5fvN2ANqGiDdNGsm0CSM4/qAJvHHMG5gxcQSzJo+kY/xw3xDezHKpbolAUhtwLfAOoAtYImlRRDxRVuxMYGb6dyzw9fTfutj6WoFvPbCab/xyFRu37mDiyH047qDxHHvQBA4/cAyzJo/ybB0zazn1bBHMAVZGxCoASbcAc4HyRDAX+FZEBPCgpLGS9o+ItbUO5udPvsBff+8RXtrWzYmzJvHfTn0TR08b54FbM2t59UwEU4Bny7a7eP23/b7KTAH+JBFImgfMA+jo6NitYGZMHMkRU8dy6WkzOapj3G4dw8wsj+qZCPr6qh27UYaIWAgsBOjs7Hzd/ixmTBzBNy+aszsvNTPLtXqOfnYBU8u2DwTW7EYZMzOro3omgiXATEkzJA0DzgUW9SqzCLhQieOATfUYHzAzs/7VrWsoIgqSLgHuIpk+ekNELJM0P92/AFhMMnV0Jcn00YvqFY+ZmfWtrr8jiIjFJJV9+XMLyh4HcHE9YzAzs8r8CykzsxbnRGBm1uKcCMzMWpwTgZlZi1MyXts8JK0DVu/myycC62sYTrNoxetuxWuG1rzuVrxmGPh1T4uISX3taLpEsCckLY2IzkbHMdha8bpb8ZqhNa+7Fa8Zanvd7hoyM2txTgRmZi2u1RLBwkYH0CCteN2teM3QmtfditcMNbzulhojMDOz12u1FoGZmfXiRGBm1uJymQgknSHpD5JWSrqyj/2S9LV0/6OSjmpEnLWW4bovSK/3UUn3Szq8EXHWUrVrLit3jKSipPcNZnz1kuW6JZ0s6WFJyyTdO9gx1lqG/77HSPqRpEfSa2761Ywl3SDpRUmP97O/NnVZROTqj2TJ6z8CBwHDgEeA2b3KnAX8hOQOaccBv2l03IN03ScA49LHZzb7dWe55rJyPydZCfd9jY57kD7rsST3B+9It/drdNyDcM1XAf+cPp4EbASGNTr2PbzuE4GjgMf72V+TuiyPLYI5wMqIWBURO4BbgLm9yswFvhWJB4GxkvYf7EBrrOp1R8T9EfFSuvkgyR3hmlmWzxrgUuA24MXBDK6Oslz3+cDtEfEMQEQ0+7VnueYARkkSMJIkERQGN8zaioj7SK6jPzWpy/KYCKYAz5Ztd6XPDbRMsxnoNX2E5JtEM6t6zZKmAO8FFpAfWT7rWcA4SfdIekjShYMWXX1kueZrgDeT3O72MeCyiCgNTngNU5O6rK43pmkQ9fFc7zmyWco0m8zXJOkUkkTw1rpGVH9ZrvkrwBURUUy+KOZClutuB44GTgPeADwg6cGIWFHv4OokyzWfDjwMnAocDNwt6ZcRsbnOsTVSTeqyPCaCLmBq2faBJN8QBlqm2WS6JklvAa4HzoyIDYMUW71kueZO4JY0CUwEzpJUiIg7BiXC+sj63/j6iNgKbJV0H3A40KyJIMs1XwR8MZLO85WSngIOBX47OCE2RE3qsjx2DS0BZkqaIWkYcC6wqFeZRcCF6Yj7ccCmiFg72IHWWNXrltQB3A58sIm/GZares0RMSMipkfEdOD7wMebPAlAtv/Gfwi8TVK7pOHAscDyQY6zlrJc8zMkLSAkTQYOAVYNapSDryZ1We5aBBFRkHQJcBfJTIMbImKZpPnp/gUks0fOAlYC20i+STS1jNf9GWACcF36DbkQTbxqY8Zrzp0s1x0RyyX9FHgUKAHXR0SfUxCbQcbP+mrgRkmPkXSZXBERTb08taSbgZOBiZK6gL8HhkJt6zIvMWFm1uLy2DVkZmYD4ERgZtbinAjMzFqcE4GZWYtzIjAza3FOBLbXkvQ/0lUkH01X0Tw2ff56SbN385gHSPp+2fbN6fE/Ielzkt5eq/j3lKQtdTz2ZyVdXq/jW3PJ3e8ILB8kHQ+8GzgqIl6TNJFk1Uki4qO7e9yIWAO8Lz3HG4ETImJaDUI2a1puEdjean+SJRJeA4iI9WklTrqQWmf6+COSVqTPfUPSNenzN6brtN8vaVXPfQgkTS9b2/1nwH5pa+Nt6Wt6yh2TvvYRSb+VNCp97S8l/S79OyEte3J6/u9LelLSt9MVMPs7TpukL0lakrZG/irrmyLpYEk/TReS+6WkQ5Wsw/+0pCFpmeGSnpU0tK/yNfhsLGecCGxv9TNgalrJXyfppN4FJB0AfJpkHfZ3kKwrU25/koX13g18sY9znA38MSKOiIhflh13GPBdktUrDwfeDrxKsoz1OyLiKOADwNfKjnUk8N+B2SRr5v9ZheN8hGQpgGOAY4D/KmlGxvdlIXBpRBwNXA5cFxGbSNbn73mP3gPcFRHdfZXPeB5rIe4asr1SRGyRdDTwNuAU4LuSroyIG8uKzQHujYiNAJJuJVl+uccd6TLET6Rrz2R1CLA2IpaksWxOjz8CuEbSEUCx17l+GxFdabmHgenApn6O807gLdp1t7QxwEzgqUpBSRpJcnOhW7VrJdV90n+/S5KcfkGyDs91Vcqb7eREYHutiCgC9wD3pOvHfAi4saxItXWlXxtA2XKi76V8PwG8QLKK5xBgez/nKpL8v9XfcUTyLf2uAcREes6XI+KIPvYtAr4gaTzJ8tM/B0ZUKG+2k7uGbK8k6RBJM8ueOgJY3avYb4GTJI2T1A78RY1O/yRwgKRj0lhGpccfQ/INvwR8kGTxs905zl3AxyQNTZ+flbY2KkpbFE9Jen/6Oim973REbCF5P74K3BkRxUrlzcq5RWB7q5HA/5I0luR2gyuBeeUFIuI5SZ8HfkOyBvsTJN0xeyQidkj6QHr+N5D067+dpH/9trRi/QWwdTePcz1J19Hv0kHldcA5fRxiuJIVJ3t8GbgA+LqkvyNZhfIWkvEBSLqHbiVZrbJHpfJmgFcftSYnaWQ6ntAO/IBkeeIfNDous2biriFrdp9NB2cfJxlsvaOh0Zg1IbcIzMxanFsEZmYtzonAzKzFORGYmbU4JwIzsxbnRGBm1uL+P4KCiepOeVmAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100)  # a range of significance levels\n",
    "err = np.zeros(100)  # the corresponding error rates\n",
    "for k in range(100):\n",
    "    eps[k] = k/100 # considering eps = k%\n",
    "    err[k] = 0 # initializing the error rate \n",
    "    for j in range(d_y_test.shape[0]):\n",
    "        if (test_sample_p[j,int(d_y_test[j])] <= eps[k]): # if we made an error \n",
    "            err[k] = err[k] + 1 # count this error\n",
    "    err[k] = err[k] / d_y_test.shape[0] # number of errors -> error rate \n",
    "\n",
    "figure = plt.plot(eps,err)\n",
    "plt.title('Calibration Curve')\n",
    "plt.xlabel('Significance Level')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1bb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59cd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52b28abf",
   "metadata": {},
   "source": [
    "<h1>Implementing SVC for Wine Dataset </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaffed7",
   "metadata": {},
   "source": [
    "<h1> Task 4 : Implementing the default version of SVC on Wine Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8930a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score : 0.6695156695156694\n",
      "Error Rate : 0.33048433048433057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=311)\n",
    "svc.fit(x_train, y_train)\n",
    "cross_scores = cross_val_score(svc, x_train, y_train, cv=5)\n",
    "print(\"Average Score :\",np.mean(cross_scores))\n",
    "print(\"Error Rate :\", 1-np.mean(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f900c",
   "metadata": {},
   "source": [
    "<h3> Trying different parameter values for SVC</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ba427c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SVC : SVC(C=0.01, degree=1, random_state=311)\n",
      "Average Score : 0.39088319088319085\n",
      "Error Rate : 0.6091168091168091\n",
      "\n",
      "\n",
      "For SVC : SVC(C=0.1, degree=2, random_state=311)\n",
      "Average Score : 0.6621082621082621\n",
      "Error Rate : 0.3378917378917379\n",
      "\n",
      "\n",
      "For SVC : SVC(C=1, random_state=311)\n",
      "Average Score : 0.6695156695156694\n",
      "Error Rate : 0.33048433048433057\n",
      "\n",
      "\n",
      "For SVC : SVC(C=10, degree=4, random_state=311)\n",
      "Average Score : 0.6925925925925925\n",
      "Error Rate : 0.30740740740740746\n",
      "\n",
      "\n",
      "For SVC : SVC(C=100, degree=5, random_state=311)\n",
      "Average Score : 0.752991452991453\n",
      "Error Rate : 0.24700854700854702\n",
      "\n",
      "\n",
      "For SVC : SVC(C=1000, degree=6, random_state=311)\n",
      "Average Score : 0.8809116809116808\n",
      "Error Rate : 0.11908831908831918\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "degree_list = [1,2,3, 4, 5, 6]\n",
    "for i in range(len(c_list)):\n",
    "    svc = SVC(C = c_list[i], degree = degree_list[i], random_state=311)\n",
    "    svc.fit(x_train, y_train)\n",
    "    cross_scores = cross_val_score(svc, x_train, y_train, cv=5)\n",
    "    print(\"For SVC : {}\".format(svc))\n",
    "    print(\"Average Score :\",np.mean(cross_scores))\n",
    "    print(\"Error Rate :\", 1-np.mean(cross_scores))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96483e7a",
   "metadata": {},
   "source": [
    "In the above outputs, we can see the average score and error rate for our SVC model when we try different values of <b>C</b> and <b>degree</b><br>\n",
    "\n",
    "<h3>Observations </h3>\n",
    "We can see that as we keep increasing the values of both C and degree the accuracy of the model keeps on increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4bbed",
   "metadata": {},
   "source": [
    "<h1>Task 5 : SVC with the paramaeters that give the best accuracy</h1>\n",
    "We select c=1000 and degree=6 and run the SVC model for it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "677dcbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration : SVC(C=1000, degree=6, random_state=311)\n",
      "Test Accuracy : 0.8888888888888888\n",
      "Test Error Rate : 0.11111111111111116\n"
     ]
    }
   ],
   "source": [
    "new_svc = SVC(C=1000, degree = 6, random_state=311)\n",
    "new_svc.fit(x_train, y_train)\n",
    "svc_acc = new_svc.score(x_test, y_test)\n",
    "print(\"Configuration :\", new_svc)\n",
    "print(\"Test Accuracy :\",svc_acc)\n",
    "d_err_rate = 1 - svc_acc\n",
    "print(\"Test Error Rate :\",d_err_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3b5b3",
   "metadata": {},
   "source": [
    "<h3>Observations</h3>\n",
    "Step 4 Accuracy : 0.88091<br>\n",
    "Step 5 Accuracy : 0.88888<br><br>\n",
    "\n",
    "Step 4 Error Rate : 0.1111<br>\n",
    "Step 5 Error Rate : 0.033<br>\n",
    "\n",
    "From the above numbers we can say that the model performs slightly lower when trained on the entire training dataset.</br>\n",
    "The reason might be that, the size of the dataset is too small to be ran with cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c48285",
   "metadata": {},
   "source": [
    "<h1>Task 6 : Creating a pipeline for SVC with data normalization.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b50ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MinMax Scaler :\n",
      "0.9555555555555556\n",
      "\n",
      "\n",
      "For Normalizer Scaler :\n",
      "0.9555555555555556\n",
      "\n",
      "\n",
      "For Standard Scaler :\n",
      "0.9555555555555556\n",
      "\n",
      "\n",
      "For Robust Scaler :\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with MinMAx Scaler\n",
    "mm_scaler_pipeline = Pipeline([(\"MinMaxScaler\", MinMaxScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "mm_scaler_pipeline.fit(x_train, y_train)\n",
    "print(\"For MinMax Scaler :\")\n",
    "print(mm_scaler_pipeline.score(x_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Normalizer Scaler\n",
    "n_scaler_pipeline = Pipeline([(\"Normalizer\", Normalizer()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "n_scaler_pipeline.fit(x_train, y_train)\n",
    "print(\"For Normalizer Scaler :\")\n",
    "print(n_scaler_pipeline.score(x_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Standard Scaler\n",
    "ss_scaler_pipeline = Pipeline([(\"StandardScaler\", StandardScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "ss_scaler_pipeline.fit(x_train, y_train)\n",
    "print(\"For Standard Scaler :\")\n",
    "print(ss_scaler_pipeline.score(x_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Standard Scaler\n",
    "rs_scaler_pipeline = Pipeline([(\"Robust\", RobustScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "rs_scaler_pipeline.fit(x_train, y_train)\n",
    "print(\"For Robust Scaler :\")\n",
    "print(rs_scaler_pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8cff0",
   "metadata": {},
   "source": [
    "In the above output we can see that all the scalers give the same output on the wine dataset</br>\n",
    "Therefore we can use any of the scalers to create the GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7056a8",
   "metadata": {},
   "source": [
    "<h1> Task 7 : Fitting the GridSearchCV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7300e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalizer\n",
      "Best Parameter value : {'svc__C': 1000, 'svc__gamma': 5}\n",
      "Model Accuracy : 0.9333333333333333\n",
      "For Robust Scale\n",
      "Best Parameter value : {'svc__C': 10, 'svc__gamma': 1}\n",
      "Model Accuracy : 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Implementing GridSearchCV using the Normalizer Scaler method\n",
    "param_vals = {'svc__C':[0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'svc__gamma':[1,2,3, 4, 5, 6]}\n",
    "\n",
    "grid_search_pipe = GridSearchCV(n_scaler_pipeline, param_vals, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(x_train, y_train)\n",
    "print(\"For Normalizer\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# Implementing GridSearchCV using the Robust Scaler method\n",
    "grid_search_pipe = GridSearchCV(rs_scaler_pipeline, param_vals, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(x_train, y_train)\n",
    "print(\"For Robust Scale\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8b552",
   "metadata": {},
   "source": [
    "<h1>Implementing SVC for USPS Dataset </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb37b89",
   "metadata": {},
   "source": [
    "<h1> Task 3 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d00dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score : 0.97103089019505\n",
      "Error Rate : 0.028969109804950044\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=311)\n",
    "svc.fit(d_x_train, d_y_train)\n",
    "cross_scores = cross_val_score(svc, d_x_train, d_y_train, cv=5)\n",
    "print(\"Average Score :\",np.mean(cross_scores))\n",
    "print(\"Error Rate :\", 1-np.mean(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72e013",
   "metadata": {},
   "source": [
    "<h1> Task 4</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a3d0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SVC : SVC(C=0.01, degree=1, random_state=311)\n",
      "Average Score : 0.6506512807063555\n",
      "Error Rate : 0.3493487192936445\n",
      "\n",
      "\n",
      "For SVC : SVC(C=0.1, degree=2, random_state=311)\n",
      "Average Score : 0.9424935334742341\n",
      "Error Rate : 0.057506466525765854\n",
      "\n",
      "\n",
      "For SVC : SVC(C=1, random_state=311)\n",
      "Average Score : 0.97103089019505\n",
      "Error Rate : 0.028969109804950044\n",
      "\n",
      "\n",
      "For SVC : SVC(C=10, degree=4, random_state=311)\n",
      "Average Score : 0.9736126666769513\n",
      "Error Rate : 0.026387333323048656\n",
      "\n",
      "\n",
      "For SVC : SVC(C=100, degree=5, random_state=311)\n",
      "Average Score : 0.9736126666769513\n",
      "Error Rate : 0.026387333323048656\n",
      "\n",
      "\n",
      "For SVC : SVC(C=1000, degree=6, random_state=311)\n",
      "Average Score : 0.9727524516231879\n",
      "Error Rate : 0.027247548376812092\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "degree_list = [1,2,3, 4, 5, 6]\n",
    "for i in range(len(c_list)):\n",
    "    svc = SVC(C = c_list[i], degree = degree_list[i], random_state=311)\n",
    "    svc.fit(d_x_train, d_y_train)\n",
    "    cross_scores = cross_val_score(svc, d_x_train, d_y_train, cv=5)\n",
    "    print(\"For SVC : {}\".format(svc))\n",
    "    print(\"Average Score :\",np.mean(cross_scores))\n",
    "    print(\"Error Rate :\", 1-np.mean(cross_scores))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc27435",
   "metadata": {},
   "source": [
    "<h1>Task 5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2b086c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration : SVC(C=1000, degree=6, random_state=311)\n",
      "Test Accuracy : 0.9759139784946237\n",
      "Test Error Rate : 0.02408602150537631\n"
     ]
    }
   ],
   "source": [
    "new_svc = SVC(C=1000, degree = 6, random_state=311)\n",
    "new_svc.fit(d_x_train, d_y_train)\n",
    "svc_acc = new_svc.score(d_x_test, d_y_test)\n",
    "print(\"Configuration :\", new_svc)\n",
    "print(\"Test Accuracy :\",svc_acc)\n",
    "d_err_rate = 1 - svc_acc\n",
    "print(\"Test Error Rate :\",d_err_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d1f64",
   "metadata": {},
   "source": [
    "<h3>Observations</h3>\n",
    "Step 4 Accuracy : 0.9727<br>\n",
    "Step 5 Accuracy : 0.9759<br><br>\n",
    "\n",
    "Step 4 Error Rate : 0.0272<br>\n",
    "Step 5 Error Rate : 0.0240<br>\n",
    "\n",
    "From the above numbers we can say that the model performs almost same when tested using cross val and normal prediction.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4862b",
   "metadata": {},
   "source": [
    "<h1>TAsk 6</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58730ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MinMax Scaler :\n",
      "0.9759139784946237\n",
      "\n",
      "\n",
      "For Normalizer Scaler :\n",
      "0.9746236559139785\n",
      "\n",
      "\n",
      "For Standard Scaler :\n",
      "0.970752688172043\n",
      "\n",
      "\n",
      "For Robust Scaler :\n",
      "0.944516129032258\n"
     ]
    }
   ],
   "source": [
    "# Creating the Pipeline with MinMAx Scaler\n",
    "mm_scaler_pipeline = Pipeline([(\"MinMaxScaler\", MinMaxScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "mm_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(\"For MinMax Scaler :\")\n",
    "print(mm_scaler_pipeline.score(d_x_test, d_y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Normalizer Scaler\n",
    "n_scaler_pipeline = Pipeline([(\"Normalizer\", Normalizer()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "n_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(\"For Normalizer Scaler :\")\n",
    "print(n_scaler_pipeline.score(d_x_test, d_y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Standard Scaler\n",
    "ss_scaler_pipeline = Pipeline([(\"StandardScaler\", StandardScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "ss_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(\"For Standard Scaler :\")\n",
    "print(ss_scaler_pipeline.score(d_x_test, d_y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating the Pipeline with Standard Scaler\n",
    "rs_scaler_pipeline = Pipeline([(\"Robust\", RobustScaler()), \\\n",
    "                      (\"svc\", SVC(random_state=311, C=1000, degree = 6)) \\\n",
    "                     ])\n",
    "rs_scaler_pipeline.fit(d_x_train, d_y_train)\n",
    "print(\"For Robust Scaler :\")\n",
    "print(rs_scaler_pipeline.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019abee8",
   "metadata": {},
   "source": [
    "<h1> Task 7</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f45849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalizer\n",
      "Best Parameter value : {'svc__C': 10, 'svc__gamma': 2}\n",
      "Model Accuracy : 0.9767741935483871\n"
     ]
    }
   ],
   "source": [
    "# Implementing GridSearchCV using the Normalizer Scaler method\n",
    "param_vals = {'svc__C':[0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'svc__gamma':[1,2,3, 4, 5, 6]}\n",
    "\n",
    "grid_search_pipe = GridSearchCV(n_scaler_pipeline, param_vals, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(d_x_train, d_y_train)\n",
    "print(\"For Normalizer\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(d_x_test, d_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing GridSearchCV using the Robust Scaler method\n",
    "grid_search_pipe = GridSearchCV(ss_scaler_pipeline, param_vals, cv=5, n_jobs = -2)\n",
    "grid_search_pipe.fit(d_x_train, d_y_train)\n",
    "print(\"For Standard Scale\")\n",
    "print(\"Best Parameter value :\",grid_search_pipe.best_params_)\n",
    "print(\"Model Accuracy :\",grid_search_pipe.score(d_x_test, d_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebc5aa",
   "metadata": {},
   "source": [
    "<h1> Fun Observation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ced70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usps digits data is the data of images of handwritten number\n",
    "# Each observations is 257 elements long, out of which the first element is the label(0-9)\n",
    "# So basically, there are 256 pixel values. If we imagine it in a grid structure, it shouold be a 16x16 matrix.\n",
    "# So if we reshape the features and zoom out and see, then we should be able to see the figure vaguely\n",
    "\n",
    "# Example:\n",
    "# Lets take any one row from the training data\n",
    "data_row = training_data[2]\n",
    "print(training_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see that the first row is a label.\n",
    "# Now lets reshape the feature data into a 16x16 np array\n",
    "\n",
    "# if we really zoom out on the screen(by pressing Ctrl -), then we will be able to see a vague \n",
    "# pattern which represents the label number\n",
    "print(np.reshape(data_row[1:],(16,16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a5b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
